{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acc2a676-4ae7-47e7-b8f2-669ec5acbd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You're very clever.</td>\n",
       "      <td>Vous êtes fort ingénieuse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are there kids?</td>\n",
       "      <td>Y a-t-il des enfants ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Come in.</td>\n",
       "      <td>Entrez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where's Boston?</td>\n",
       "      <td>Où est Boston ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You see what I mean?</td>\n",
       "      <td>Vous voyez ce que je veux dire ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     en                                fr\n",
       "0   You're very clever.        Vous êtes fort ingénieuse.\n",
       "1       Are there kids?            Y a-t-il des enfants ?\n",
       "2              Come in.                          Entrez !\n",
       "3       Where's Boston?                   Où est Boston ?\n",
       "4  You see what I mean?  Vous voyez ce que je veux dire ?"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('data/en-fr.csv', names=['en', 'fr'], usecols=['en', 'fr'])\n",
    "df = pd.read_csv('data/en-fr.txt', names=['en', 'fr', 'attr'], usecols=['en', 'fr'], sep='\\t')\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "731a821e-f036-4dfe-845d-2f298674e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youre very clever</td>\n",
       "      <td>[start] vous etes fort ingenieuse [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are there kids</td>\n",
       "      <td>[start] y atil des enfants  [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come in</td>\n",
       "      <td>[start] entrez [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wheres boston</td>\n",
       "      <td>[start] ou est boston [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you see what i mean</td>\n",
       "      <td>[start] vous voyez ce que je veux dire  [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    en                                             fr\n",
       "0    youre very clever        [start] vous etes fort ingenieuse [end]\n",
       "1       are there kids              [start] y atil des enfants  [end]\n",
       "2              come in                           [start] entrez [end]\n",
       "3        wheres boston                    [start] ou est boston [end]\n",
       "4  you see what i mean  [start] vous voyez ce que je veux dire  [end]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text by removing punctuation symbols and numbers, converting characters to lowercase,\n",
    "# and replacing Unicode characters with their ASCII equivalents. \n",
    "# For the French samples, insert [start] and [end] tokens at the beginning and end of each phrase\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "def clean_text(text):\n",
    "    text = normalize('NFD', text.lower())\n",
    "    text = re.sub('[^A-Za-z ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def clean_and_prepare_text(text):\n",
    "    text = '[start] ' + clean_text(text) + ' [end]'\n",
    "    return text\n",
    "\n",
    "df['en'] = df['en'].apply(lambda row: clean_text(row))\n",
    "df['fr'] = df['fr'].apply(lambda row: clean_and_prepare_text(row))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "505fad25-8bbb-4316-8c2a-94ed3a92bf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max phrase length (English): 7\n",
      "Max phrase length (French): 16\n",
      "Sequence length: 16\n"
     ]
    }
   ],
   "source": [
    "# scan the phrases and determine the maximum length of the English phrases and then of the French phrases. \n",
    "# These lengths will determine the lengths of the sequences input to and output from the model\n",
    "\n",
    "en = df['en']\n",
    "fr = df['fr']\n",
    "\n",
    "en_max_len = max(len(line.split()) for line in en)\n",
    "fr_max_len = max(len(line.split()) for line in fr)\n",
    "sequence_len = max(en_max_len, fr_max_len)\n",
    "\n",
    "print(f'Max phrase length (English): {en_max_len}')\n",
    "print(f'Max phrase length (French): {fr_max_len}')\n",
    "print(f'Sequence length: {sequence_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "264f756b-f77f-4da8-b53a-451042d83cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit one Tokenizer to the English phrases and another Tokenizer to their French equivalents, \n",
    "# and generate padded sequences for all the phrases:\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "en_tokenizer = Tokenizer()\n",
    "en_tokenizer.fit_on_texts(en)\n",
    "en_sequences = en_tokenizer.texts_to_sequences(en)\n",
    "en_x = pad_sequences(en_sequences, maxlen=sequence_len, padding='post')\n",
    "\n",
    "fr_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n')\n",
    "fr_tokenizer.fit_on_texts(fr)\n",
    "fr_sequences = fr_tokenizer.texts_to_sequences(fr)\n",
    "fr_y = pad_sequences(fr_sequences, maxlen=sequence_len + 1, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c79a25aa-1e0a-461f-9afb-01ece4296e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (English): 6033\n",
      "Vocabulary size (French): 12197\n"
     ]
    }
   ],
   "source": [
    "# Compute the vocabulary sizes from the Tokenizer instances:\n",
    "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
    "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
    "\n",
    "print(f'Vocabulary size (English): {en_vocab_size}')\n",
    "print(f'Vocabulary size (French): {fr_vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ccb49ba0-19a0-4dc1-884f-e8ac89aaa271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, create the features and the labels the model will be trained with.\n",
    "# The features are the padded English sequences and the padded French sequences minus the [end] tokens.\n",
    "# The labels are the padded French sequences minus the [start] tokens. \n",
    "# Package the features in a dictionary so they can be input to a model that accepts multiple inputs.\n",
    "\n",
    "inputs = { 'encoder_input': en_x, 'decoder_input': fr_y[:, :-1] }\n",
    "outputs = fr_y[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f16a1d4c-c087-4164-84aa-b3f6636f7551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ token_and_position_embedding_40   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548,544</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)       │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ transformer_encoder_20            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">395,776</span> │ token_and_position_embeddi\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ functional_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12197</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,920,613</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "│                                   │                              │                   │ transformer_encoder_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
       "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ token_and_position_embedding_40   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,548,544\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)       │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ transformer_encoder_20            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m395,776\u001b[0m │ token_and_position_embeddi\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)              │                              │                   │                           \n",
       "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
       "│ functional_37 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12197\u001b[0m)          │         \u001b[38;5;34m6,920,613\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "│                                   │                              │                   │ transformer_encoder_20[\u001b[38;5;34m0\u001b[0m][\n",
       "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,864,933</span> (33.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,864,933\u001b[0m (33.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,864,933</span> (33.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,864,933\u001b[0m (33.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now use Keras's functional API to define a model that includes a transformer encoder and a transformer decoder. \n",
    "# The model accepts two inputs: padded English sequences for the encoder, and padded French sequences for the decoder. \n",
    "# The output from the decoder is fed to a softmax output layer for classification.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from keras_nlp.layers import TokenAndPositionEmbedding, TransformerEncoder\n",
    "from keras_nlp.layers import TransformerDecoder\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "num_heads = 8\n",
    "embed_dim = 256\n",
    "\n",
    "encoder_input = Input(shape=(None,), dtype='int64', name='encoder_input')\n",
    "x = TokenAndPositionEmbedding(en_vocab_size, sequence_len, embed_dim)(encoder_input)\n",
    "encoder_output = TransformerEncoder(embed_dim, num_heads)(x)\n",
    "encoded_seq_input = Input(shape=(None, embed_dim))\n",
    "\n",
    "decoder_input = Input(shape=(None,), dtype='int64', name='decoder_input')\n",
    "x = TokenAndPositionEmbedding(fr_vocab_size, sequence_len, embed_dim, mask_zero=True)(decoder_input)\n",
    "x = TransformerDecoder(embed_dim, num_heads)(x, encoded_seq_input)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "decoder_output = Dense(fr_vocab_size, activation='softmax')(x)\n",
    "decoder = Model([decoder_input, encoded_seq_input], decoder_output)\n",
    "decoder_output = decoder([decoder_input, encoder_output])\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8fcc662a-387e-496c-b2f8-86d21aaf791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:53:23.388650: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: indices[24,2] = 9018 is not in [0, 6033)\n",
      "\t [[{{function_node __inference_one_step_on_data_118004}}{{node functional_38_1/token_and_position_embedding_40_1/token_embedding_1/GatherV2}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_38_1/token_and_position_embedding_40_1/token_embedding_1/GatherV2 defined at (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/4m/qtpm281n73j20b82dbnh980w0000gq/T/ipykernel_62857/3041662429.py\", line 7, in <module>\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/models/functional.py\", line 560, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras_nlp/src/layers/modeling/token_and_position_embedding.py\", line 138, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras_nlp/src/layers/modeling/reversible_embedding.py\", line 141, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/core/embedding.py\", line 140, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 4918, in take\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1967, in take\n\nindices[24,2] = 9018 is not in [0, 6033)\n\t [[{{node functional_38_1/token_and_position_embedding_40_1/token_embedding_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_118311]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      6\u001b[0m callback \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/personal/final-year-project/env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_38_1/token_and_position_embedding_40_1/token_embedding_1/GatherV2 defined at (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/4m/qtpm281n73j20b82dbnh980w0000gq/T/ipykernel_62857/3041662429.py\", line 7, in <module>\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/models/functional.py\", line 560, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras_nlp/src/layers/modeling/token_and_position_embedding.py\", line 138, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras_nlp/src/layers/modeling/reversible_embedding.py\", line 141, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/layers/core/embedding.py\", line 140, in call\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 4918, in take\n\n  File \"/Users/enyiomaosondu/personal/final-year-project/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1967, in take\n\nindices[24,2] = 9018 is not in [0, 6033)\n\t [[{{node functional_38_1/token_and_position_embedding_40_1/token_embedding_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_118311]"
     ]
    }
   ],
   "source": [
    "# Train the model, and use an EarlyStopping callback to end training if the validation accuracy fails \n",
    "# to improve for three consecutive epochs:\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "hist = model.fit(inputs, outputs, epochs=50, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f282a1e-4448-41ec-ba8f-e2924884a6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
